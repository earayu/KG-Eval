# KG-Eval Examples

> ğŸŒ **ä¸­æ–‡æ–‡æ¡£**: [README-zh.md](../README-zh.md)

This directory contains examples demonstrating how to use the KG-Eval framework.

## Files

- `sample_usage.py` - Complete example showing framework usage
- `base_url_example.py` - Examples of using custom base URLs for LLM APIs
- `sample_kg.json` - Sample knowledge graph data (generated by running sample_usage.py)

## Running the Example

1. Install the KG-Eval package:
```bash
# If you haven't cloned the repository yet:
# git clone https://github.com/earayu/KG-Eval.git
# cd KG-Eval

# Install dependencies
uv sync
```

2. Configure environment (optional, for advanced semantic evaluation):
```bash
# Copy the environment template
cp env.template .env

# Edit .env file to add your API keys
# You only need ONE of OpenAI or Anthropic for full functionality
# Without API keys, you can still use 3 out of 4 evaluation dimensions
```

3. Run the sample usage script:
```bash
python examples/sample_usage.py
```

This will:
- Create a sample knowledge graph about the Three Kingdoms period
- Evaluate it across all four dimensions
- Generate JSON and HTML reports
- Show usage of the evaluation framework

4. Run the base URL configuration example:
```bash
python examples/base_url_example.py
```

This will show you how to:
- Configure OpenAI with custom base URLs (proxies, Azure, LocalAI)
- Configure Anthropic with custom endpoints
- Use environment variables for configuration
- Set up different model configurations

## CLI Examples

After running `sample_usage.py`, you can try the CLI commands:

```bash
# Basic evaluation
kg-eval evaluate examples/sample_kg.json --output examples/cli_report.json

# HTML report
kg-eval evaluate examples/sample_kg.json --output examples/report.html --format html

# Evaluate specific dimensions only
kg-eval evaluate examples/sample_kg.json --dimensions scale_richness structural_integrity

# Generate radar chart
kg-eval radar examples/sample_kg.json --output examples/radar.html

# With LLM referee for full semantic evaluation
# (API keys are automatically read from .env file)
kg-eval evaluate examples/sample_kg.json --output examples/full_report.json

# With custom OpenAI configuration (proxy, Azure, etc.)
kg-eval evaluate examples/sample_kg.json \
  --openai-model gpt-3.5-turbo \
  --openai-base-url https://your-proxy.com/v1 \
  --output examples/proxy_report.json

# With Anthropic referee
kg-eval evaluate examples/sample_kg.json \
  --anthropic-key "your-key" \
  --anthropic-model claude-3-sonnet-20240229 \
  --output examples/anthropic_report.json
```

## Sample Knowledge Graph Format

The sample knowledge graph follows the KG-Eval data format:

```json
{
  "entities": [
    {
      "entity_name": "æ›¹æ“",
      "entity_type": "Person",
      "description": "é­å›½çš„å»ºç«‹è€…ï¼Œä¸œæ±‰æœ«å¹´è‘—åæ”¿æ²»å®¶ã€å†›äº‹å®¶"
    }
  ],
  "relationships": [
    {
      "source_entity_name": "æ›¹æ“",
      "target_entity_name": "é­å›½",
      "description": "å»ºç«‹äº†é­å›½",
      "keywords": ["åˆ›å»º", "ç»Ÿæ²»"],
      "weight": 0.9
    }
  ],
  "source_texts": [
    {
      "content": "æ›¹æ“æ˜¯ä¸œæ±‰æœ«å¹´è‘—åçš„æ”¿æ²»å®¶ã€å†›äº‹å®¶ï¼Œä»–ç»Ÿä¸€äº†åŒ—æ–¹ï¼Œå»ºç«‹äº†é­å›½æ”¿æƒã€‚",
      "linked_entity_names": ["æ›¹æ“", "é­å›½"],
      "linked_edges": [["æ›¹æ“", "é­å›½"]]
    }
  ]
}
``` 